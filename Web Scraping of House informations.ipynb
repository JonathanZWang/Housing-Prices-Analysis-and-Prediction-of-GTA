{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # library to handle data in a vectorized manner\n",
    "import pandas as pd  # library for data analsysis\n",
    "from bs4 import BeautifulSoup\n",
    "import json  # library to handle JSON files\n",
    "import requests  # library to handle requests\n",
    "from urllib import request\n",
    "from pandas.io.json import json_normalize  # tranform JSON file into a pandas dataframe\n",
    "\n",
    "print(\"Libraries imported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CSV files is exported from my Web Scraping of School informations.ipynb file\n",
    "school = pd.read_csv(\"school_scores.csv\")\n",
    "school = school.iloc[:, 1:]\n",
    "\n",
    "# Since the origin csv file includes all of the schools in Ontario, here we need to define the Cities belongs to GTA\n",
    "# Due to project objective, I didn't selected all of the cities in GTA\n",
    "GTA = [\n",
    "    \"Toronto\",\n",
    "    \"Mississauga\",\n",
    "    \"Ajax\",\n",
    "    \"Brampton\",\n",
    "    \"Unionville\",\n",
    "    \"Oakville\",\n",
    "    \"Richmond Hill\",\n",
    "    \"Markham\",\n",
    "    \"Oshawa\",\n",
    "    \"Whitby\",\n",
    "    \"Caledon\",\n",
    "    \"Pickering\",\n",
    "    \"Maple\",\n",
    "    \"Thornhill\",\n",
    "    \"Woodbridge\",\n",
    "    \"Aurora\",\n",
    "    \"Vaughan\",\n",
    "    \"Concord\",\n",
    "    \"Stouffville\",\n",
    "    \"Milton\",\n",
    "    \"Newmarket\",\n",
    "    \"King City\",\n",
    "    \"Durham\",\n",
    "]\n",
    "school = school[school[\"school_city\"].isin(GTA)]\n",
    "school.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping House informations close to the school\n",
    "n = 0\n",
    "address_list = []\n",
    "num_bedroom_list = []\n",
    "num_bathroom_list = []\n",
    "price_list = []\n",
    "post_code_list = []\n",
    "latitude_list = []\n",
    "longitude_list = []\n",
    "neighborhood_list = []\n",
    "ptype_list = []\n",
    "size_list = []\n",
    "\n",
    "for post_code in school.school_post_code:\n",
    "    n += 1\n",
    "    for ptype in [\"house\", \"condo\", \"townhouse\"]:\n",
    "        url = \"for Security issue, here I just delete the url link of the listing website\".format(\n",
    "            post_code, ptype\n",
    "        )\n",
    "        print(\"loading school number:\", n, \"for house type\", ptype, url)\n",
    "        # Fetch the html file\n",
    "        html_doc = requests.get(url).text\n",
    "        soup = BeautifulSoup(html_doc)\n",
    "\n",
    "        headings = soup.findAll(\n",
    "            \"ul\",\n",
    "            {\n",
    "                \"class\": \"headings-menu list-unstyled xs-flex xs-flex-wrap xs-text-5 sm-mt1\"\n",
    "            },\n",
    "        )[0]\n",
    "        containers1 = soup.findAll(\"li\", {\"class\": \"listing-column text-4\"})\n",
    "        containers2 = soup.findAll(\"span\", {\"itemprop\": \"geo\"})\n",
    "        containers3 = soup.findAll(\"span\", {\"class\": \"neighbourhood\"})\n",
    "        containers4 = soup.findAll(\"span\", {\"class\": \"xs-mr05\"})\n",
    "\n",
    "        if (\n",
    "            headings.findAll(\"li\", {\"class\": \"xs-pr1 xs-mt1 xs-hide sm-block\"})[0]\n",
    "            .contents[0]\n",
    "            .contents[0]\n",
    "            == \"Zero Homes for Sale\"\n",
    "        ):\n",
    "            print(\"Zero Homes for Sale\")\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            for i in range(len(containers1)):\n",
    "                try:\n",
    "                    address = (\n",
    "                        containers1[i]\n",
    "                        .findAll(\"span\", {\"class\": \"street\"})[0]\n",
    "                        .contents[0]\n",
    "                    )\n",
    "                    num_bedroom = (\n",
    "                        containers1[i]\n",
    "                        .findAll(\"li\", {\"class\": \"xs-inline xs-mr05\"})[0]\n",
    "                        .contents[0]\n",
    "                    )\n",
    "                    num_bathroom = (\n",
    "                        containers1[i]\n",
    "                        .findAll(\"li\", {\"class\": \"xs-inline xs-mr05\"})[1]\n",
    "                        .contents[1]\n",
    "                    )\n",
    "\n",
    "                    try:\n",
    "                        size = (\n",
    "                            containers1[i]\n",
    "                            .findAll(\"li\", {\"class\": \"xs-inline xs-mr05\"})[2]\n",
    "                            .contents[1]\n",
    "                        )\n",
    "                    except:\n",
    "                        size = \"\"\n",
    "\n",
    "                    price = (\n",
    "                        containers1[i]\n",
    "                        .findAll(\"span\", {\"itemprop\": \"price\"})[0]\n",
    "                        .contents[0]\n",
    "                    )\n",
    "\n",
    "                    latitude = float(\n",
    "                        str(containers2[i].findAll(\"meta\")[0])\n",
    "                        .strip()\n",
    "                        .split()[1]\n",
    "                        .strip(\"content=\")\n",
    "                        .strip('\"')\n",
    "                    )\n",
    "                    longitude = float(\n",
    "                        str(containers2[i].findAll(\"meta\")[1])\n",
    "                        .strip()\n",
    "                        .split()[1]\n",
    "                        .strip(\"content=\")\n",
    "                        .strip('\"')\n",
    "                    )\n",
    "\n",
    "                    neighborhood = containers3[2].contents[1]\n",
    "\n",
    "                    address_list.append(address)\n",
    "                    num_bedroom_list.append(num_bedroom)\n",
    "                    num_bathroom_list.append(num_bathroom)\n",
    "                    price_list.append(price)\n",
    "                    post_code_list.append(post_code)\n",
    "                    latitude_list.append(latitude)\n",
    "                    longitude_list.append(longitude)\n",
    "                    neighborhood_list.append(neighborhood)\n",
    "                    ptype_list.append(ptype)\n",
    "                    size_list.append(size)\n",
    "\n",
    "                    print(address)\n",
    "                    time.sleep(0.5)\n",
    "                except:\n",
    "                    print(\"Require Sign In to view listing\")\n",
    "            time.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create House DataSet from last step\n",
    "house = pd.DataFrame(\n",
    "    [\n",
    "        address_list,\n",
    "        num_bedroom_list,\n",
    "        num_bathroom_list,\n",
    "        price_list,\n",
    "        post_code_list,\n",
    "        latitude_list,\n",
    "        longitude_list,\n",
    "        neighborhood_list,\n",
    "        ptype_list,\n",
    "        size_list,\n",
    "    ]\n",
    ").T\n",
    "house.columns = [\n",
    "    \"address\",\n",
    "    \"num_bedroom\",\n",
    "    \"num_bathroom\",\n",
    "    \"price\",\n",
    "    \"post_code\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"neighborhood\",\n",
    "    \"ptype\",\n",
    "    \"size\",\n",
    "]\n",
    "house.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save House Dataset into CSV file\n",
    "house.to_csv(\n",
    "    \"house.csv\",\n",
    "    header=[\n",
    "        \"address\",\n",
    "        \"num_bedroom\",\n",
    "        \"num_bathroom\",\n",
    "        \"price\",\n",
    "        \"post_code\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"neighborhood\",\n",
    "        \"ptype\",\n",
    "        \"size\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
